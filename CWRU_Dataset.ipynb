{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from IPython.core.debugger import set_trace\n",
    "from pathlib import Path\n",
    "\n",
    "# Pytorch\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch import Tensor\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch import optim\n",
    "from torch.nn.modules.loss import CrossEntropyLoss\n",
    "\n",
    "\n",
    "from one_cycle import OneCycle, update_lr, update_mom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_dir = Path()\n",
    "normal_path = working_dir / 'Data' / 'Normal'\n",
    "DE_path = working_dir / 'Data' / '12k_DE'\n",
    "FE_path = working_dir / 'Data' / '12k_FE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data which is in matlab format into dic for further preprocessing\n",
    "normal_data = {}\n",
    "for i, filepath in enumerate(normal_path.glob('*.mat')):\n",
    "    key_name = str(filepath).split('\\\\')[-1]    #strip the folder path and get the filename only.\n",
    "    normal_data[key_name] = scipy.io.loadmat(filepath)\n",
    "\n",
    "DE_data = {}\n",
    "for i, filepath in enumerate(DE_path.glob('*.mat')):\n",
    "    key_name = str(filepath).split('\\\\')[-1]    #strip the folder path and get the filename only.\n",
    "    DE_data[key_name] = scipy.io.loadmat(filepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove redundant information of the matlab data.\n",
    "for key, values in normal_data.items():\n",
    "    del values['__header__']\n",
    "    del values['__version__']    \n",
    "    del values['__globals__']    \n",
    "    \n",
    "for key, values in DE_data.items():\n",
    "    del values['__header__']\n",
    "    del values['__version__']    \n",
    "    del values['__globals__']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k1,v1 in DE_data.items():\n",
    "    del_list = []\n",
    "    for k2,v2 in list(v1.items()):\n",
    "        if 'DE_time' in k2:\n",
    "            v1['DE_time'] = v1.pop(k2)\n",
    "        elif 'BA_time' in k2:\n",
    "            v1['BA_time'] = v1.pop(k2)\n",
    "        elif 'FE_time' in k2:\n",
    "            v1['FE_time'] = v1.pop(k2)\n",
    "        elif 'RPM' in k2:\n",
    "            v1['RPM'] = v1.pop(k2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k1,v1 in normal_data.items():\n",
    "    del_list = []\n",
    "    for k2,v2 in list(v1.items()):\n",
    "        if 'DE_time' in k2:\n",
    "            v1['DE_time'] = v1.pop(k2)\n",
    "        elif 'BA_time' in k2:\n",
    "            v1['BA_time'] = v1.pop(k2)\n",
    "        elif 'FE_time' in k2:\n",
    "            v1['FE_time'] = v1.pop(k2)\n",
    "        elif 'RPM' in k2:\n",
    "            v1['RPM'] = v1.pop(k2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(train_ds, valid_ds, bs):\n",
    "    return (\n",
    "        DataLoader(train_ds, batch_size=bs, shuffle=True),\n",
    "        DataLoader(valid_ds, batch_size=bs * 2),\n",
    "    )\n",
    "\n",
    "def loss_batch(model, loss_func, xb, yb, opt=None):\n",
    "    loss = loss_func(model(xb), yb)\n",
    "\n",
    "    if opt is not None:\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "    return loss.item(), len(xb)\n",
    "\n",
    "def fit(epochs, model, loss_func, opt, train_dl, valid_dl):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for xb, yb in train_dl:\n",
    "            loss_batch(model, loss_func, xb, yb, opt)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            losses, nums = zip(\n",
    "                *[loss_batch(model, loss_func, xb, yb) for xb, yb in valid_dl]\n",
    "            )\n",
    "        val_loss = np.sum(np.multiply(losses, nums)) / np.sum(nums)\n",
    "\n",
    "        print(f'EPOCH {epoch}: \\t', val_loss)\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit2(epochs, model, loss_func, opt, train_dl, valid_dl):\n",
    "    print('EPOCH', '\\t', 'Val Loss', '\\t', 'Accuracy')\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for xb, yb in train_dl:\n",
    "            loss_batch(model, loss_func, xb, yb, opt)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            loss = [loss_func(model(xb), yb) for xb, yb in valid_dl]\n",
    "            loss = torch.stack(loss, dim=0).numpy()\n",
    "            predictions = [torch.argmax(model(xb), dim=1) for xb, yb in valid_dl]\n",
    "#             set_trace()\n",
    "            predictions = torch.cat(predictions, dim=0).numpy()\n",
    "#         set_trace()\n",
    "        val_loss = np.mean(loss)\n",
    "        accuracy = np.mean((predictions == valid_dl.dataset.tensors[1].numpy()))\n",
    "\n",
    "        print(f'{epoch}: \\t', f'{val_loss:.05f}', '\\t', f'{accuracy:.05f}')\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_one_cycle(epochs, model, loss_func, opt, train_dl, valid_dl, one_cycle_scheduler):\n",
    "    print('EPOCH', '\\t', 'Val Loss', '\\t', 'Accuracy')\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for xb, yb in train_dl:\n",
    "            loss_batch(model, loss_func, xb, yb, opt)\n",
    "            lr, mom = onecycle.calc()\n",
    "            update_lr(opt, lr)\n",
    "            update_mom(opt, mom)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            loss = [loss_func(model(xb), yb) for xb, yb in valid_dl]\n",
    "            loss = torch.stack(loss, dim=0).numpy()\n",
    "            predictions = [torch.argmax(model(xb), dim=1) for xb, yb in valid_dl]\n",
    "#             set_trace()\n",
    "            predictions = torch.cat(predictions, dim=0).numpy()\n",
    "#         set_trace()\n",
    "        val_loss = np.mean(loss)\n",
    "        accuracy = np.mean((predictions == valid_dl.dataset.tensors[1].numpy()))\n",
    "\n",
    "        print(f'{epoch}: \\t', f'{val_loss:.05f}', '\\t', f'{accuracy:.05f}')\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_BE = pd.DataFrame.from_dict(DE_data).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Normal = pd.DataFrame.from_dict(normal_data).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label(x):\n",
    "    if 'B' in x:\n",
    "        return 'B'\n",
    "    elif 'IR' in x:\n",
    "        return 'IR'\n",
    "    elif 'OR' in x:\n",
    "        return 'OR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Normal = df_Normal.reset_index()\n",
    "df_Normal['label'] = 'N'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_BE = df_BE.reset_index()\n",
    "df_BE['label'] = df_BE['index'].apply(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Normal = df_Normal.drop(['FE_time', 'RPM', 'ans'], axis=1)\n",
    "df_BE = df_BE.drop(['FE_time','BA_time', 'RPM'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>DE_time</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Normal_0.mat</td>\n",
       "      <td>[[0.05319692307692307], [0.08866153846153846],...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Normal_1.mat</td>\n",
       "      <td>[[0.046104], [-0.03713353846153846], [-0.08949...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Normal_2.mat</td>\n",
       "      <td>[[0.06425353846153846], [0.06300184615384616],...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Normal_3.mat</td>\n",
       "      <td>[[0.014603076923076923], [0.05444861538461539]...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          index                                            DE_time label\n",
       "0  Normal_0.mat  [[0.05319692307692307], [0.08866153846153846],...     N\n",
       "1  Normal_1.mat  [[0.046104], [-0.03713353846153846], [-0.08949...     N\n",
       "2  Normal_2.mat  [[0.06425353846153846], [0.06300184615384616],...     N\n",
       "3  Normal_3.mat  [[0.014603076923076923], [0.05444861538461539]...     N"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Normal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>DE_time</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>OR007@6_1.mat</td>\n",
       "      <td>[[-0.1104558882235529], [0.21563263473053892],...</td>\n",
       "      <td>OR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>B014_1.mat</td>\n",
       "      <td>[[0.005522794411177645], [-0.10379604790419161...</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>OR007@6_0.mat</td>\n",
       "      <td>[[0.008527844311377245], [0.4235496007984032],...</td>\n",
       "      <td>OR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>OR021@6_1.mat</td>\n",
       "      <td>[[-0.025989620758483035], [-0.0272078842315369...</td>\n",
       "      <td>OR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>B021_3.mat</td>\n",
       "      <td>[[0.07244606786427145], [0.04791836327345309],...</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            index                                            DE_time label\n",
       "41  OR007@6_1.mat  [[-0.1104558882235529], [0.21563263473053892],...    OR\n",
       "5      B014_1.mat  [[0.005522794411177645], [-0.10379604790419161...     B\n",
       "40  OR007@6_0.mat  [[0.008527844311377245], [0.4235496007984032],...    OR\n",
       "57  OR021@6_1.mat  [[-0.025989620758483035], [-0.0272078842315369...    OR\n",
       "11     B021_3.mat  [[0.07244606786427145], [0.04791836327345309],...     B"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_BE.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_length = 2048\n",
    "normal_dic = {}\n",
    "idx = 0\n",
    "for i in range(df_Normal.shape[0]):\n",
    "    n = len(df_Normal.iloc[i,1])\n",
    "    num_segments = n // segment_length\n",
    "    for segment in range(num_segments):\n",
    "        normal_dic[idx] = {\n",
    "            'signal': df_Normal.iloc[i,1][segment*segment_length:segment*segment_length+segment_length],\n",
    "            'label': df_Normal.iloc[i,2],\n",
    "            'filename' : df_Normal.iloc[i,0]\n",
    "                          }\n",
    "        idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "faulty_dic = {}\n",
    "idx = 0\n",
    "for i in range(df_BE.shape[0]):\n",
    "    n = len(df_BE.iloc[i,1])\n",
    "    num_segments = n // segment_length\n",
    "    for segment in range(num_segments):\n",
    "        faulty_dic[idx] = {\n",
    "            'signal': df_BE.iloc[i,1][segment*segment_length:segment*segment_length+segment_length],\n",
    "            'label': df_BE.iloc[i,2],\n",
    "            'filename' : df_BE.iloc[i,0]\n",
    "                          }\n",
    "        idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normal_tmp = pd.DataFrame.from_dict(normal_dic,orient='index')\n",
    "df_faulty_tmp = pd.DataFrame.from_dict(faulty_dic,orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normal_processed = pd.concat([df_normal_tmp, pd.DataFrame(np.hstack(df_normal_tmp[\"signal\"].values).T)], axis=1 )\n",
    "df_faulty_processed = pd.concat([df_faulty_tmp, pd.DataFrame(np.hstack(df_faulty_tmp[\"signal\"].values).T)], axis=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.concat([df_normal_processed, df_faulty_processed], axis=0, ignore_index=True).drop(['signal'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_label = {'N':0, 'B':1, 'IR':2, 'OR':3}\n",
    "df_all['label'] = df_all['label'].map(map_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.label.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048\n"
     ]
    }
   ],
   "source": [
    "features = df_all.columns[2:]\n",
    "target = 'label'\n",
    "print(len(features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1D CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seg_length 1000, lowest loss 0.011\n",
    "class CNN_1D(nn.Module):\n",
    "    def __init__(self, n_in):\n",
    "        super().__init__()\n",
    "        self.n_in = n_in\n",
    "        self.conv_in = nn.Conv1d(1, 32, (9,), stride=1, padding=4)\n",
    "        self.conv_1 = nn.Conv1d(32, 64, (5,), stride=1, padding=2)\n",
    "        self.conv_2 = nn.Conv1d(64, 128, (5,), stride=1, padding=2)\n",
    "        self.maxpool = nn.MaxPool1d(2,stride=2)\n",
    "        self.averagepool = nn.AvgPool1d(2,stride=2)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.linear1 = nn.Linear(self.n_in*64 //4, 50)\n",
    "        self.linear2 = nn.Linear(50, 4)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 1, self.n_in)\n",
    "        x = F.relu(self.conv_in(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = F.relu(self.conv_1(x))\n",
    "        x = self.averagepool(x)\n",
    "        x = x.view(-1, self.n_in*64//4)\n",
    "        x = self.linear1(x)\n",
    "        return self.linear2(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seg_length 1000, lowest loss 0.014\n",
    "class CNN_1D(nn.Module):\n",
    "    def __init__(self, n_in):\n",
    "        super().__init__()\n",
    "        self.n_in = n_in\n",
    "        self.conv_in = nn.Conv1d(1, 32, (9,), stride=1, padding=4)\n",
    "        self.conv_1 = nn.Conv1d(32, 64, (5,), stride=1, padding=2)\n",
    "        self.conv_2 = nn.Conv1d(64, 128, (5,), stride=1, padding=2)\n",
    "        self.maxpool = nn.MaxPool1d(2,stride=2)\n",
    "        self.averagepool = nn.AvgPool1d(2,stride=2)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.linear1 = nn.Linear(self.n_in*64 //4, 4)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 1, self.n_in)\n",
    "        x = F.relu(self.conv_in(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = F.relu(self.conv_1(x))\n",
    "        x = self.averagepool(x)\n",
    "        x = x.view(-1, self.n_in*64//4)\n",
    "        return self.linear1(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seg_length 1000, lowest loss \n",
    "class CNN_1D(nn.Module):\n",
    "    def __init__(self, n_in):\n",
    "        super().__init__()\n",
    "        self.n_in = n_in\n",
    "        self.conv_in = nn.Conv1d(1, 32, (9,), stride=1, padding=4)\n",
    "        self.conv_1 = nn.Conv1d(32, 64, (5,), stride=1, padding=2)\n",
    "        self.conv_2 = nn.Conv1d(64, 128, (5,), stride=1, padding=2)\n",
    "        self.maxpool = nn.MaxPool1d(2,stride=2)\n",
    "        self.averagepool = nn.AvgPool1d(2,stride=2)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.linear1 = nn.Linear(self.n_in*64 //4, 4)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 1, self.n_in)\n",
    "        x = self.dropout(F.relu(self.conv_in(x)))\n",
    "        x = self.maxpool(x)\n",
    "        x = self.dropout(F.relu(self.conv_1(x)))\n",
    "        x = self.averagepool(x)\n",
    "        x = x.view(-1, self.n_in*64//4)\n",
    "        return self.linear1(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_1D(nn.Module):\n",
    "    def __init__(self, n_in):\n",
    "        super().__init__()\n",
    "        self.n_in = n_in\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv1d(1, 32, (9,), stride=1, padding=4),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2,stride=2)\n",
    "        )\n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv1d(32, 64, (5,), stride=1, padding=2),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv1d(64, 128, (5,), stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.AvgPool1d(2,stride=2)\n",
    "        )\n",
    "        \n",
    "        self.linear1 = nn.Linear(self.n_in*128 //4, 50)\n",
    "        self.linear2 = nn.Linear(50, 4)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 1, self.n_in)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = x.view(-1, self.n_in*128//4)\n",
    "        x = self.linear1(x)\n",
    "        return self.linear2(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_1D(nn.Module):\n",
    "    def __init__(self, n_in):\n",
    "        super().__init__()\n",
    "        self.n_in = n_in\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv1d(1, 64, (9,), stride=1, padding=4),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2,stride=2)\n",
    "        )\n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv1d(64, 128, (5,), stride=1, padding=2),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv1d(128, 128, (5,), stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.AvgPool1d(2,stride=2)\n",
    "        )\n",
    "        \n",
    "        self.linear1 = nn.Linear(self.n_in*128 //4, 4)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 1, self.n_in)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = x.view(-1, self.n_in*128//4)\n",
    "        x = self.linear1(x)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_1D(nn.Module):\n",
    "    def __init__(self, n_in):\n",
    "        super().__init__()\n",
    "        self.n_in = n_in\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv1d(1, 64, (9,), stride=1, padding=4),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.MaxPool1d(2,stride=2)\n",
    "        )\n",
    "        \n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv1d(64, 128, (5,), stride=1, padding=2),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.AvgPool1d(2,stride=2)\n",
    "        )\n",
    "        \n",
    "        self.linear1 = nn.Linear(self.n_in*128 //4, 4)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 1, self.n_in)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = x.view(-1, self.n_in*128//4)\n",
    "        return self.linear1(x)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_1D(nn.Module):\n",
    "    def __init__(self, n_in):\n",
    "        super().__init__()\n",
    "        self.n_in = n_in\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv1d(1, 64, (9,), stride=1, padding=4),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.MaxPool1d(2,stride=2)\n",
    "        )\n",
    "        \n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv1d(64, 64, (5,), stride=1, padding=2),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.MaxPool1d(2,stride=2)\n",
    "        )\n",
    "        \n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv1d(64, 128, (5,), stride=1, padding=2),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.MaxPool1d(2,stride=2)\n",
    "        )\n",
    "        \n",
    "        self.linear1 = nn.Linear(self.n_in*128 //8, 4)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 1, self.n_in)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = x.view(-1, self.n_in*128//8)\n",
    "        return self.linear1(x)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_1D(nn.Module):\n",
    "    def __init__(self, n_in, layers = [1, 64, 64, 128]):\n",
    "        super().__init__()\n",
    "        self.n_in = n_in\n",
    "        self.layers = layers\n",
    "        for layer_num, layer_size in layers[:-1]:\n",
    "            setattr(f'layer_{layer_num + 1}') = nn.Sequential(\n",
    "                nn.Conv1d(layers[layer_num], layers[layer_num + 1], (5,), stride=1, padding=2),\n",
    "                nn.BatchNorm1d(layers[layer_num + 1]),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(p=0.5),\n",
    "                nn.MaxPool1d(2,stride=2)\n",
    "            )\n",
    "        \n",
    "        self.linear1 = nn.Linear(self.n_in*layers[-1] // 2**(len(layers)-1), 4)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 1, self.n_in)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = x.view(-1, self.n_in*128//8)\n",
    "        return self.linear1(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(df_all[features], \n",
    "                                                      df_all[target], \n",
    "                                                      test_size=0.20, random_state=42, shuffle=True\n",
    "                                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.01\n",
    "bs = 64\n",
    "wd = 1e-3\n",
    "epochs = 20\n",
    "loss_func = CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "X_valid = torch.tensor(X_valid.values, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train.values, dtype=torch.long)\n",
    "y_valid = torch.tensor(y_valid.values, dtype=torch.long)\n",
    "\n",
    "train_ds = TensorDataset(X_train, y_train)\n",
    "valid_ds = TensorDataset(X_valid, y_valid)\n",
    "train_dl, valid_dl = get_data(train_ds, valid_ds, bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model = CNN_1D(len(features))\n",
    "opt = optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=wd)\n",
    "# opt = optim.Adam(model.parameters(), lr=lr, betas=(0.9, 0.999), weight_decay=wd)\n",
    "model = fit2(epochs, model, loss_func, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model = CNN_1D(1000)\n",
    "# opt = optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=wd)\n",
    "opt = optim.Adam(model.parameters(), lr=lr, betas=(0.9, 0.999), weight_decay=wd)\n",
    "model = fit2(epochs, model, loss_func, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.01\n",
    "bs = 64\n",
    "wd = 1e-3\n",
    "epochs = 10\n",
    "model = fit2(epochs, model, loss_func, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for xb, _ in valid_dl:\n",
    "        pred = F.softmax(model(xb),dim=1)\n",
    "        prob, pred = torch.max(pred,1)\n",
    "#         print(pred.shape)\n",
    "        predictions.append(pred)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(y_valid.numpy() == torch.cat(predictions, dim=0).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sum(y_valid.numpy() == torch.cat(predictions, dim=0).numpy()))\n",
    "print(len(y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit One Cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.03\n",
    "bs = 64\n",
    "wd = 1e-3\n",
    "epochs = 10\n",
    "loss_func = CrossEntropyLoss()\n",
    "onecycle = OneCycle(int(len(X_train) * epochs / bs), lr, prcnt=(epochs - 82) * 100/epochs, momentum_vals=(0.95, 0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH \t Val Loss \t Accuracy\n",
      "0: \t 2.79584 \t 0.35240\n",
      "1: \t 0.70464 \t 0.77460\n",
      "2: \t 0.36010 \t 0.85240\n",
      "3: \t 0.26214 \t 0.88330\n",
      "4: \t 0.16237 \t 0.94050\n",
      "5: \t 0.48454 \t 0.82609\n",
      "6: \t 0.14245 \t 0.94279\n",
      "7: \t 0.33786 \t 0.85126\n",
      "8: \t 0.10058 \t 0.96453\n",
      "9: \t 0.08943 \t 0.96224\n",
      "Wall time: 10min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = CNN_1D(len(features))\n",
    "opt = optim.SGD(model.parameters(), lr=lr/10, momentum=0.95, weight_decay=wd)\n",
    "# opt = optim.Adam(model.parameters(), lr=lr, betas=(0.9, 0.999), weight_decay=wd)\n",
    "model = fit_one_cycle(epochs, model, loss_func, opt, train_dl, valid_dl, onecycle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
