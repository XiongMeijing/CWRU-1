{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from IPython.core.debugger import set_trace\n",
    "from pathlib import Path\n",
    "\n",
    "# Pytorch\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch import Tensor\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch import optim\n",
    "from torch.nn.modules.loss import CrossEntropyLoss\n",
    "\n",
    "\n",
    "from one_cycle import OneCycle, update_lr, update_mom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_dir = Path()\n",
    "normal_path = working_dir / 'Data' / 'Normal'\n",
    "DE_path = working_dir / 'Data' / '12k_DE'\n",
    "FE_path = working_dir / 'Data' / '12k_FE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matfile_to_dic(folder_path):\n",
    "    output_dic = {}\n",
    "    for i, filepath in enumerate(folder_path.glob('*.mat')):\n",
    "        key_name = str(filepath).split('\\\\')[-1]    #strip the folder path and get the filename only.\n",
    "        output_dic[key_name] = scipy.io.loadmat(filepath)\n",
    "    return output_dic\n",
    "\n",
    "def remove_dic_items(dic):\n",
    "    for key, values in dic.items():\n",
    "        del values['__header__']\n",
    "        del values['__version__']    \n",
    "        del values['__globals__']\n",
    "        \n",
    "def rename_keys(dic):\n",
    "    for k1,v1 in dic.items():\n",
    "        for k2,v2 in list(v1.items()):\n",
    "            if 'DE_time' in k2:\n",
    "                v1['DE_time'] = v1.pop(k2)\n",
    "            elif 'BA_time' in k2:\n",
    "                v1['BA_time'] = v1.pop(k2)\n",
    "            elif 'FE_time' in k2:\n",
    "                v1['FE_time'] = v1.pop(k2)\n",
    "            elif 'RPM' in k2:\n",
    "                v1['RPM'] = v1.pop(k2)\n",
    "                \n",
    "def label(x):\n",
    "    if 'B' in x:\n",
    "        return 'B'\n",
    "    elif 'IR' in x:\n",
    "        return 'IR'\n",
    "    elif 'OR' in x:\n",
    "        return 'OR'\n",
    "    elif 'Normal' in x:\n",
    "        return 'N'\n",
    "    \n",
    "def matfile_to_df(folder_path):\n",
    "    dic = matfile_to_dic(folder_path)\n",
    "    remove_dic_items(dic)\n",
    "    rename_keys(dic)\n",
    "    df = pd.DataFrame.from_dict(dic).T\n",
    "    df = df.reset_index().rename(mapper={'index':'filename'},axis=1)\n",
    "    df['label'] = df['filename'].apply(label)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Normal = matfile_to_df(normal_path)\n",
    "df_DE = matfile_to_df(DE_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Normal = df_Normal.drop(['FE_time', 'RPM', 'ans'], axis=1)\n",
    "df_DE = df_DE.drop(['FE_time','BA_time', 'RPM'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_signal(df, segment_length):\n",
    "    dic = {}\n",
    "    idx = 0\n",
    "    for i in range(df.shape[0]):\n",
    "        n_sample_points = len(df.iloc[i,1])\n",
    "        n_segments = n_sample_points // segment_length\n",
    "        for segment in range(n_segments):\n",
    "            dic[idx] = {\n",
    "                'signal': df.iloc[i,1][segment_length * segment:segment_length * (segment+1)], \n",
    "                'label': df.iloc[i,2],\n",
    "                'filename' : df.iloc[i,0]\n",
    "            }\n",
    "            idx += 1\n",
    "    df_tmp = pd.DataFrame.from_dict(dic,orient='index')\n",
    "    \n",
    "    return pd.concat([df_tmp[['label', 'filename']], pd.DataFrame(np.hstack(df_tmp[\"signal\"].values).T)], axis=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normal_processed = divide_signal(df_Normal, 2048)\n",
    "df_faulty_processed = divide_signal(df_DE, 2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.concat([df_normal_processed, df_faulty_processed], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_label = {'N':0, 'B':1, 'IR':2, 'OR':3}\n",
    "df_all['label'] = df_all['label'].map(map_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>filename</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>2038</th>\n",
       "      <th>2039</th>\n",
       "      <th>2040</th>\n",
       "      <th>2041</th>\n",
       "      <th>2042</th>\n",
       "      <th>2043</th>\n",
       "      <th>2044</th>\n",
       "      <th>2045</th>\n",
       "      <th>2046</th>\n",
       "      <th>2047</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3144</th>\n",
       "      <td>3</td>\n",
       "      <td>OR007@3_3.mat</td>\n",
       "      <td>0.890551</td>\n",
       "      <td>0.589640</td>\n",
       "      <td>-0.654614</td>\n",
       "      <td>-0.858876</td>\n",
       "      <td>0.413803</td>\n",
       "      <td>1.098061</td>\n",
       "      <td>-0.009340</td>\n",
       "      <td>-0.949839</td>\n",
       "      <td>...</td>\n",
       "      <td>1.940694</td>\n",
       "      <td>-1.730340</td>\n",
       "      <td>-2.009323</td>\n",
       "      <td>1.165472</td>\n",
       "      <td>2.337442</td>\n",
       "      <td>-0.415022</td>\n",
       "      <td>-2.162418</td>\n",
       "      <td>-0.507204</td>\n",
       "      <td>1.928511</td>\n",
       "      <td>1.083848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>0</td>\n",
       "      <td>Normal_3.mat</td>\n",
       "      <td>-0.027954</td>\n",
       "      <td>-0.106811</td>\n",
       "      <td>-0.114113</td>\n",
       "      <td>-0.063419</td>\n",
       "      <td>0.001669</td>\n",
       "      <td>0.019401</td>\n",
       "      <td>-0.007093</td>\n",
       "      <td>-0.017315</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002086</td>\n",
       "      <td>-0.069886</td>\n",
       "      <td>-0.104516</td>\n",
       "      <td>-0.062793</td>\n",
       "      <td>0.015229</td>\n",
       "      <td>0.055700</td>\n",
       "      <td>0.069678</td>\n",
       "      <td>0.090539</td>\n",
       "      <td>0.124335</td>\n",
       "      <td>0.176489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1872</th>\n",
       "      <td>2</td>\n",
       "      <td>IR007_1.mat</td>\n",
       "      <td>0.060101</td>\n",
       "      <td>-0.318698</td>\n",
       "      <td>0.221886</td>\n",
       "      <td>0.597761</td>\n",
       "      <td>-0.024690</td>\n",
       "      <td>-0.328769</td>\n",
       "      <td>0.159511</td>\n",
       "      <td>0.250637</td>\n",
       "      <td>...</td>\n",
       "      <td>0.204019</td>\n",
       "      <td>-0.101684</td>\n",
       "      <td>-0.191673</td>\n",
       "      <td>0.144405</td>\n",
       "      <td>0.358819</td>\n",
       "      <td>0.051330</td>\n",
       "      <td>-0.102821</td>\n",
       "      <td>-0.067248</td>\n",
       "      <td>-0.061238</td>\n",
       "      <td>-0.304891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3454</th>\n",
       "      <td>3</td>\n",
       "      <td>OR014@6_0.mat</td>\n",
       "      <td>-0.158295</td>\n",
       "      <td>-0.047419</td>\n",
       "      <td>0.157645</td>\n",
       "      <td>0.017863</td>\n",
       "      <td>-0.056148</td>\n",
       "      <td>0.099508</td>\n",
       "      <td>0.081807</td>\n",
       "      <td>-0.091023</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.085826</td>\n",
       "      <td>-0.039056</td>\n",
       "      <td>0.083187</td>\n",
       "      <td>0.012504</td>\n",
       "      <td>-0.020340</td>\n",
       "      <td>-0.073200</td>\n",
       "      <td>-0.001665</td>\n",
       "      <td>0.067841</td>\n",
       "      <td>-0.120213</td>\n",
       "      <td>0.038934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4310</th>\n",
       "      <td>3</td>\n",
       "      <td>OR021@6_3.mat</td>\n",
       "      <td>-0.081218</td>\n",
       "      <td>-0.015025</td>\n",
       "      <td>-0.043451</td>\n",
       "      <td>-0.115735</td>\n",
       "      <td>0.021929</td>\n",
       "      <td>0.133603</td>\n",
       "      <td>0.043857</td>\n",
       "      <td>0.057664</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017462</td>\n",
       "      <td>-0.097867</td>\n",
       "      <td>-0.017056</td>\n",
       "      <td>-0.006903</td>\n",
       "      <td>-0.047918</td>\n",
       "      <td>-0.041015</td>\n",
       "      <td>-0.008934</td>\n",
       "      <td>0.082030</td>\n",
       "      <td>0.110456</td>\n",
       "      <td>0.032487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>0</td>\n",
       "      <td>Normal_1.mat</td>\n",
       "      <td>-0.086367</td>\n",
       "      <td>-0.033796</td>\n",
       "      <td>0.013977</td>\n",
       "      <td>0.026286</td>\n",
       "      <td>0.009596</td>\n",
       "      <td>-0.025034</td>\n",
       "      <td>-0.021070</td>\n",
       "      <td>-0.022948</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026703</td>\n",
       "      <td>0.097632</td>\n",
       "      <td>0.144570</td>\n",
       "      <td>0.148326</td>\n",
       "      <td>0.114738</td>\n",
       "      <td>0.097632</td>\n",
       "      <td>0.114113</td>\n",
       "      <td>0.125378</td>\n",
       "      <td>0.104934</td>\n",
       "      <td>0.049442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3910</th>\n",
       "      <td>3</td>\n",
       "      <td>OR021@3_0.mat</td>\n",
       "      <td>-0.291246</td>\n",
       "      <td>-0.180465</td>\n",
       "      <td>-0.002761</td>\n",
       "      <td>0.044995</td>\n",
       "      <td>0.058964</td>\n",
       "      <td>0.041096</td>\n",
       "      <td>-0.016731</td>\n",
       "      <td>0.153339</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077319</td>\n",
       "      <td>-0.046132</td>\n",
       "      <td>-0.317723</td>\n",
       "      <td>-0.467163</td>\n",
       "      <td>-0.387570</td>\n",
       "      <td>-0.417946</td>\n",
       "      <td>-0.569985</td>\n",
       "      <td>-0.300180</td>\n",
       "      <td>-0.151552</td>\n",
       "      <td>-0.163897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2621</th>\n",
       "      <td>2</td>\n",
       "      <td>IR028_2.mat</td>\n",
       "      <td>0.541177</td>\n",
       "      <td>2.103266</td>\n",
       "      <td>0.194498</td>\n",
       "      <td>-2.443841</td>\n",
       "      <td>-1.973872</td>\n",
       "      <td>0.234374</td>\n",
       "      <td>0.474038</td>\n",
       "      <td>-0.806476</td>\n",
       "      <td>...</td>\n",
       "      <td>0.301513</td>\n",
       "      <td>-0.107422</td>\n",
       "      <td>-1.230466</td>\n",
       "      <td>-1.477047</td>\n",
       "      <td>-0.321044</td>\n",
       "      <td>0.166422</td>\n",
       "      <td>-0.528563</td>\n",
       "      <td>-0.540770</td>\n",
       "      <td>0.585936</td>\n",
       "      <td>0.915118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3899</th>\n",
       "      <td>3</td>\n",
       "      <td>OR021@3_0.mat</td>\n",
       "      <td>0.144405</td>\n",
       "      <td>0.164709</td>\n",
       "      <td>0.147004</td>\n",
       "      <td>0.167795</td>\n",
       "      <td>0.033299</td>\n",
       "      <td>-0.296607</td>\n",
       "      <td>-0.913535</td>\n",
       "      <td>-0.690024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040771</td>\n",
       "      <td>0.190212</td>\n",
       "      <td>0.247876</td>\n",
       "      <td>0.117278</td>\n",
       "      <td>0.029726</td>\n",
       "      <td>0.257785</td>\n",
       "      <td>0.253561</td>\n",
       "      <td>-0.033624</td>\n",
       "      <td>-0.124913</td>\n",
       "      <td>0.038010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1856</th>\n",
       "      <td>2</td>\n",
       "      <td>IR007_1.mat</td>\n",
       "      <td>0.017543</td>\n",
       "      <td>0.209216</td>\n",
       "      <td>0.306840</td>\n",
       "      <td>0.204993</td>\n",
       "      <td>0.043045</td>\n",
       "      <td>-0.033624</td>\n",
       "      <td>0.029563</td>\n",
       "      <td>-0.032487</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083167</td>\n",
       "      <td>-0.210516</td>\n",
       "      <td>-0.056365</td>\n",
       "      <td>0.200445</td>\n",
       "      <td>0.045482</td>\n",
       "      <td>-0.071959</td>\n",
       "      <td>0.044020</td>\n",
       "      <td>0.050192</td>\n",
       "      <td>-0.126212</td>\n",
       "      <td>-0.110781</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 2050 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label       filename         0         1         2         3         4  \\\n",
       "3144      3  OR007@3_3.mat  0.890551  0.589640 -0.654614 -0.858876  0.413803   \n",
       "674       0   Normal_3.mat -0.027954 -0.106811 -0.114113 -0.063419  0.001669   \n",
       "1872      2    IR007_1.mat  0.060101 -0.318698  0.221886  0.597761 -0.024690   \n",
       "3454      3  OR014@6_0.mat -0.158295 -0.047419  0.157645  0.017863 -0.056148   \n",
       "4310      3  OR021@6_3.mat -0.081218 -0.015025 -0.043451 -0.115735  0.021929   \n",
       "238       0   Normal_1.mat -0.086367 -0.033796  0.013977  0.026286  0.009596   \n",
       "3910      3  OR021@3_0.mat -0.291246 -0.180465 -0.002761  0.044995  0.058964   \n",
       "2621      2    IR028_2.mat  0.541177  2.103266  0.194498 -2.443841 -1.973872   \n",
       "3899      3  OR021@3_0.mat  0.144405  0.164709  0.147004  0.167795  0.033299   \n",
       "1856      2    IR007_1.mat  0.017543  0.209216  0.306840  0.204993  0.043045   \n",
       "\n",
       "             5         6         7  ...      2038      2039      2040  \\\n",
       "3144  1.098061 -0.009340 -0.949839  ...  1.940694 -1.730340 -2.009323   \n",
       "674   0.019401 -0.007093 -0.017315  ... -0.002086 -0.069886 -0.104516   \n",
       "1872 -0.328769  0.159511  0.250637  ...  0.204019 -0.101684 -0.191673   \n",
       "3454  0.099508  0.081807 -0.091023  ... -0.085826 -0.039056  0.083187   \n",
       "4310  0.133603  0.043857  0.057664  ... -0.017462 -0.097867 -0.017056   \n",
       "238  -0.025034 -0.021070 -0.022948  ...  0.026703  0.097632  0.144570   \n",
       "3910  0.041096 -0.016731  0.153339  ...  0.077319 -0.046132 -0.317723   \n",
       "2621  0.234374  0.474038 -0.806476  ...  0.301513 -0.107422 -1.230466   \n",
       "3899 -0.296607 -0.913535 -0.690024  ...  0.040771  0.190212  0.247876   \n",
       "1856 -0.033624  0.029563 -0.032487  ...  0.083167 -0.210516 -0.056365   \n",
       "\n",
       "          2041      2042      2043      2044      2045      2046      2047  \n",
       "3144  1.165472  2.337442 -0.415022 -2.162418 -0.507204  1.928511  1.083848  \n",
       "674  -0.062793  0.015229  0.055700  0.069678  0.090539  0.124335  0.176489  \n",
       "1872  0.144405  0.358819  0.051330 -0.102821 -0.067248 -0.061238 -0.304891  \n",
       "3454  0.012504 -0.020340 -0.073200 -0.001665  0.067841 -0.120213  0.038934  \n",
       "4310 -0.006903 -0.047918 -0.041015 -0.008934  0.082030  0.110456  0.032487  \n",
       "238   0.148326  0.114738  0.097632  0.114113  0.125378  0.104934  0.049442  \n",
       "3910 -0.467163 -0.387570 -0.417946 -0.569985 -0.300180 -0.151552 -0.163897  \n",
       "2621 -1.477047 -0.321044  0.166422 -0.528563 -0.540770  0.585936  0.915118  \n",
       "3899  0.117278  0.029726  0.257785  0.253561 -0.033624 -0.124913  0.038010  \n",
       "1856  0.200445  0.045482 -0.071959  0.044020  0.050192 -0.126212 -0.110781  \n",
       "\n",
       "[10 rows x 2050 columns]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3], dtype=int64)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.label.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048\n"
     ]
    }
   ],
   "source": [
    "features = df_all.columns[2:]\n",
    "target = 'label'\n",
    "print(len(features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(train_ds, valid_ds, bs):\n",
    "    return (\n",
    "        DataLoader(train_ds, batch_size=bs, shuffle=True),\n",
    "        DataLoader(valid_ds, batch_size=bs * 2),\n",
    "    )\n",
    "\n",
    "def loss_batch(model, loss_func, xb, yb, opt=None):\n",
    "    loss = loss_func(model(xb), yb)\n",
    "\n",
    "    if opt is not None:\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "    return loss.item(), len(xb)\n",
    "\n",
    "def fit(epochs, model, loss_func, opt, train_dl, valid_dl):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for xb, yb in train_dl:\n",
    "            loss_batch(model, loss_func, xb, yb, opt)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            losses, nums = zip(\n",
    "                *[loss_batch(model, loss_func, xb, yb) for xb, yb in valid_dl]\n",
    "            )\n",
    "        val_loss = np.sum(np.multiply(losses, nums)) / np.sum(nums)\n",
    "\n",
    "        print(f'EPOCH {epoch}: \\t', val_loss)\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit2(epochs, model, loss_func, opt, train_dl, valid_dl):\n",
    "    print('EPOCH', '\\t', 'Val Loss', '\\t', 'Accuracy')\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for xb, yb in train_dl:\n",
    "            loss_batch(model, loss_func, xb, yb, opt)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            loss = [loss_func(model(xb), yb) for xb, yb in valid_dl]\n",
    "            loss = torch.stack(loss, dim=0).numpy()\n",
    "            predictions = [torch.argmax(model(xb), dim=1) for xb, yb in valid_dl]\n",
    "#             set_trace()\n",
    "            predictions = torch.cat(predictions, dim=0).numpy()\n",
    "#         set_trace()\n",
    "        val_loss = np.mean(loss)\n",
    "        accuracy = np.mean((predictions == valid_dl.dataset.tensors[1].numpy()))\n",
    "\n",
    "        print(f'{epoch}: \\t', f'{val_loss:.05f}', '\\t', f'{accuracy:.05f}')\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_one_cycle(epochs, model, loss_func, opt, train_dl, valid_dl, one_cycle_scheduler):\n",
    "    print('EPOCH', '\\t', 'Val Loss', '\\t', 'Accuracy')\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for xb, yb in train_dl:\n",
    "            loss_batch(model, loss_func, xb, yb, opt)\n",
    "            lr, mom = onecycle.calc()\n",
    "            update_lr(opt, lr)\n",
    "            update_mom(opt, mom)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            loss = [loss_func(model(xb), yb) for xb, yb in valid_dl]\n",
    "            loss = torch.stack(loss, dim=0).numpy()\n",
    "            predictions = [torch.argmax(model(xb), dim=1) for xb, yb in valid_dl]\n",
    "#             set_trace()\n",
    "            predictions = torch.cat(predictions, dim=0).numpy()\n",
    "#         set_trace()\n",
    "        val_loss = np.mean(loss)\n",
    "        accuracy = np.mean((predictions == valid_dl.dataset.tensors[1].numpy()))\n",
    "\n",
    "        print(f'{epoch}: \\t', f'{val_loss:.05f}', '\\t', f'{accuracy:.05f}')\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1D CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seg_length 1000, lowest loss 0.011\n",
    "class CNN_1D(nn.Module):\n",
    "    def __init__(self, n_in):\n",
    "        super().__init__()\n",
    "        self.n_in = n_in\n",
    "        self.conv_in = nn.Conv1d(1, 32, (9,), stride=1, padding=4)\n",
    "        self.conv_1 = nn.Conv1d(32, 64, (5,), stride=1, padding=2)\n",
    "        self.conv_2 = nn.Conv1d(64, 128, (5,), stride=1, padding=2)\n",
    "        self.maxpool = nn.MaxPool1d(2,stride=2)\n",
    "        self.averagepool = nn.AvgPool1d(2,stride=2)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.linear1 = nn.Linear(self.n_in*64 //4, 50)\n",
    "        self.linear2 = nn.Linear(50, 4)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 1, self.n_in)\n",
    "        x = F.relu(self.conv_in(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = F.relu(self.conv_1(x))\n",
    "        x = self.averagepool(x)\n",
    "        x = x.view(-1, self.n_in*64//4)\n",
    "        x = self.linear1(x)\n",
    "        return self.linear2(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seg_length 1000, lowest loss 0.014\n",
    "class CNN_1D(nn.Module):\n",
    "    def __init__(self, n_in):\n",
    "        super().__init__()\n",
    "        self.n_in = n_in\n",
    "        self.conv_in = nn.Conv1d(1, 32, (9,), stride=1, padding=4)\n",
    "        self.conv_1 = nn.Conv1d(32, 64, (5,), stride=1, padding=2)\n",
    "        self.conv_2 = nn.Conv1d(64, 128, (5,), stride=1, padding=2)\n",
    "        self.maxpool = nn.MaxPool1d(2,stride=2)\n",
    "        self.averagepool = nn.AvgPool1d(2,stride=2)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.linear1 = nn.Linear(self.n_in*64 //4, 4)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 1, self.n_in)\n",
    "        x = F.relu(self.conv_in(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = F.relu(self.conv_1(x))\n",
    "        x = self.averagepool(x)\n",
    "        x = x.view(-1, self.n_in*64//4)\n",
    "        return self.linear1(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seg_length 1000, lowest loss \n",
    "class CNN_1D(nn.Module):\n",
    "    def __init__(self, n_in):\n",
    "        super().__init__()\n",
    "        self.n_in = n_in\n",
    "        self.conv_in = nn.Conv1d(1, 32, (9,), stride=1, padding=4)\n",
    "        self.conv_1 = nn.Conv1d(32, 64, (5,), stride=1, padding=2)\n",
    "        self.conv_2 = nn.Conv1d(64, 128, (5,), stride=1, padding=2)\n",
    "        self.maxpool = nn.MaxPool1d(2,stride=2)\n",
    "        self.averagepool = nn.AvgPool1d(2,stride=2)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.linear1 = nn.Linear(self.n_in*64 //4, 4)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 1, self.n_in)\n",
    "        x = self.dropout(F.relu(self.conv_in(x)))\n",
    "        x = self.maxpool(x)\n",
    "        x = self.dropout(F.relu(self.conv_1(x)))\n",
    "        x = self.averagepool(x)\n",
    "        x = x.view(-1, self.n_in*64//4)\n",
    "        return self.linear1(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_1D(nn.Module):\n",
    "    def __init__(self, n_in):\n",
    "        super().__init__()\n",
    "        self.n_in = n_in\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv1d(1, 32, (9,), stride=1, padding=4),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2,stride=2)\n",
    "        )\n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv1d(32, 64, (5,), stride=1, padding=2),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv1d(64, 128, (5,), stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.AvgPool1d(2,stride=2)\n",
    "        )\n",
    "        \n",
    "        self.linear1 = nn.Linear(self.n_in*128 //4, 50)\n",
    "        self.linear2 = nn.Linear(50, 4)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 1, self.n_in)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = x.view(-1, self.n_in*128//4)\n",
    "        x = self.linear1(x)\n",
    "        return self.linear2(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_1D(nn.Module):\n",
    "    def __init__(self, n_in):\n",
    "        super().__init__()\n",
    "        self.n_in = n_in\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv1d(1, 64, (9,), stride=1, padding=4),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2,stride=2)\n",
    "        )\n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv1d(64, 128, (5,), stride=1, padding=2),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv1d(128, 128, (5,), stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.AvgPool1d(2,stride=2)\n",
    "        )\n",
    "        \n",
    "        self.linear1 = nn.Linear(self.n_in*128 //4, 4)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 1, self.n_in)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = x.view(-1, self.n_in*128//4)\n",
    "        x = self.linear1(x)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_1D(nn.Module):\n",
    "    def __init__(self, n_in):\n",
    "        super().__init__()\n",
    "        self.n_in = n_in\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv1d(1, 64, (9,), stride=1, padding=4),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.MaxPool1d(2,stride=2)\n",
    "        )\n",
    "        \n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv1d(64, 128, (5,), stride=1, padding=2),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.AvgPool1d(2,stride=2)\n",
    "        )\n",
    "        \n",
    "        self.linear1 = nn.Linear(self.n_in*128 //4, 4)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 1, self.n_in)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = x.view(-1, self.n_in*128//4)\n",
    "        return self.linear1(x)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_1D(nn.Module):\n",
    "    def __init__(self, n_in):\n",
    "        super().__init__()\n",
    "        self.n_in = n_in\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv1d(1, 64, (9,), stride=1, padding=4),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.MaxPool1d(2,stride=2)\n",
    "        )\n",
    "        \n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv1d(64, 64, (5,), stride=1, padding=2),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.MaxPool1d(2,stride=2)\n",
    "        )\n",
    "        \n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv1d(64, 128, (5,), stride=1, padding=2),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.MaxPool1d(2,stride=2)\n",
    "        )\n",
    "        \n",
    "        self.linear1 = nn.Linear(self.n_in*128 //8, 4)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 1, self.n_in)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = x.view(-1, self.n_in*128//8)\n",
    "        return self.linear1(x)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_1D(nn.Module):\n",
    "    def __init__(self, n_in, layers = [1, 64, 64, 128]):\n",
    "        super().__init__()\n",
    "        self.n_in = n_in\n",
    "        self.layers = layers\n",
    "        for layer_num, layer_size in layers[:-1]:\n",
    "            setattr(f'layer_{layer_num + 1}') = nn.Sequential(\n",
    "                nn.Conv1d(layers[layer_num], layers[layer_num + 1], (5,), stride=1, padding=2),\n",
    "                nn.BatchNorm1d(layers[layer_num + 1]),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(p=0.5),\n",
    "                nn.MaxPool1d(2,stride=2)\n",
    "            )\n",
    "        \n",
    "        self.linear1 = nn.Linear(self.n_in*layers[-1] // 2**(len(layers)-1), 4)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 1, self.n_in)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = x.view(-1, self.n_in*128//8)\n",
    "        return self.linear1(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(df_all[features], \n",
    "                                                      df_all[target], \n",
    "                                                      test_size=0.20, random_state=42, shuffle=True\n",
    "                                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.01\n",
    "bs = 64\n",
    "wd = 1e-3\n",
    "epochs = 20\n",
    "loss_func = CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "X_valid = torch.tensor(X_valid.values, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train.values, dtype=torch.long)\n",
    "y_valid = torch.tensor(y_valid.values, dtype=torch.long)\n",
    "\n",
    "train_ds = TensorDataset(X_train, y_train)\n",
    "valid_ds = TensorDataset(X_valid, y_valid)\n",
    "train_dl, valid_dl = get_data(train_ds, valid_ds, bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model = CNN_1D(len(features))\n",
    "opt = optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=wd)\n",
    "# opt = optim.Adam(model.parameters(), lr=lr, betas=(0.9, 0.999), weight_decay=wd)\n",
    "model = fit2(epochs, model, loss_func, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model = CNN_1D(1000)\n",
    "# opt = optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=wd)\n",
    "opt = optim.Adam(model.parameters(), lr=lr, betas=(0.9, 0.999), weight_decay=wd)\n",
    "model = fit2(epochs, model, loss_func, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.01\n",
    "bs = 64\n",
    "wd = 1e-3\n",
    "epochs = 10\n",
    "model = fit2(epochs, model, loss_func, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for xb, _ in valid_dl:\n",
    "        pred = F.softmax(model(xb),dim=1)\n",
    "        prob, pred = torch.max(pred,1)\n",
    "#         print(pred.shape)\n",
    "        predictions.append(pred)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(y_valid.numpy() == torch.cat(predictions, dim=0).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sum(y_valid.numpy() == torch.cat(predictions, dim=0).numpy()))\n",
    "print(len(y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit One Cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.03\n",
    "bs = 64\n",
    "wd = 1e-3\n",
    "epochs = 10\n",
    "loss_func = CrossEntropyLoss()\n",
    "onecycle = OneCycle(int(len(X_train) * epochs / bs), lr, prcnt=(epochs - 82) * 100/epochs, momentum_vals=(0.95, 0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH \t Val Loss \t Accuracy\n",
      "0: \t 2.79584 \t 0.35240\n",
      "1: \t 0.70464 \t 0.77460\n",
      "2: \t 0.36010 \t 0.85240\n",
      "3: \t 0.26214 \t 0.88330\n",
      "4: \t 0.16237 \t 0.94050\n",
      "5: \t 0.48454 \t 0.82609\n",
      "6: \t 0.14245 \t 0.94279\n",
      "7: \t 0.33786 \t 0.85126\n",
      "8: \t 0.10058 \t 0.96453\n",
      "9: \t 0.08943 \t 0.96224\n",
      "Wall time: 10min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = CNN_1D(len(features))\n",
    "opt = optim.SGD(model.parameters(), lr=lr/10, momentum=0.95, weight_decay=wd)\n",
    "# opt = optim.Adam(model.parameters(), lr=lr, betas=(0.9, 0.999), weight_decay=wd)\n",
    "model = fit_one_cycle(epochs, model, loss_func, opt, train_dl, valid_dl, onecycle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
